Accessible Navigator
🚏 Real-Time Audio Guidance for the Visually Impaired
📌 Problem Statement

Visually impaired individuals face challenges navigating public spaces like bus stops or train stations, where reading signs and identifying destinations is difficult.

💡 Solution

Accessible Navigator is a mobile app prototype that simulates real-time scanning of surroundings, reads aloud detected text (like bus stop names), and shows nearby transit points on a map.

Uses placeholder images (camera simulation) for hackathon MVP.

Displays dummy OCR text after 5 seconds to mimic scanning.

Provides audio output using Text-to-Speech.

Second screen shows a map placeholder with nearby bus stop information.

🎯 Features (MVP)

📷 Simulated scanning of signs (placeholder image).

🔊 Voice feedback of detected text.

🗺️ Maps screen showing nearest bus stop (placeholder map image).

🚀 Simple UI for quick demo and hackathon showcase.

🛠️ Tech Stack

Frontend: Android (Java, XML layouts)

Speech: Android Text-to-Speech (TTS)

Future Enhancements with Azure Services:

Azure Cognitive Services (OCR + Speech)

Azure Maps (real-time transit info)

Azure App Services / Functions (backend integration)

📲 App Flow (MVP)

Home Screen – Placeholder image simulates scanning.

After 5 seconds → Displays "Bus Stop: Central Station" + speaks aloud.

Maps Screen – Placeholder map image + text "Nearby Bus Stop: City Center".

📷 Demo
<img width="407" height="773" alt="Screenshot 2025-09-02 182349" src="https://github.com/user-attachments/assets/c07145ee-ffb3-481b-a7f8-eaacbc6fe4c2" />

